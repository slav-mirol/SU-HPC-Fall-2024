# Умножение матриц на CPU и GPU

Этот проект реализует умножение матриц двумя способами:
- Последовательное умножение на **CPU**
- Параллельное умножение на **GPU** с использованием технологии CUDA

## Описание функций

### `matrix_multiply_cpu(A, B)`
Функция выполняет умножение двух матриц на **CPU**.
Алгоритм использует тройной цикл для вычисления каждого элемента результирующей матрицы. 

- **Параметры:**
  - `A`: Первая матрица (numpy array)
  - `B`: Вторая матрица (numpy array)
- **Возвращает**:
  - `answer`: Результат умножения матриц
  - `время выполнения`: Время, затраченное на выполнение операции.

#### Детали реализации:
- Операция умножения матриц выполняется через тройной цикл по индексам \(i\), \(j\) и \(k\). 
- Эта операция имеет кубическую сложность \(O(N^3)\), что делает её медленной для больших матриц.
- Циклы вычисляют каждый элемент результирующей матрицы путём сложения произведений элементов соответствующих строк первой матрицы и столбцов второй матрицы.

---

### `matrix_multiply_gpu(A, B)`

Функция для умножения двух матриц на **GPU** с использованием библиотеки PyCUDA. Операция выполняется параллельно на графическом процессоре, что позволяет значительно ускорить процесс умножения.

- **Параметры:**
  - `A`: Первая входная матрица (numpy array с элементами типа `float32`).
  - `B`: Вторая входная матрица (numpy array с элементами типа `float32`).
- **Возвращает**:
  - `C`: Результат умножения матриц (numpy array с элементами типа `float32`).
  - `время выполнения`: Время, затраченное на выполнение операции в секундах.

#### Детали реализации:
- **Проверка размеров**: 
  - В начале функции осуществляется проверка соответствия размеров матриц `A` и `B`, чтобы гарантировать, что их можно перемножить. Если размеры некорректны, генерируется исключение `ValueError`.
- **Выделение памяти на GPU**: 
  - Создаются указатели на общей памяти GPU для входных и выходных данных (`A_gpu`, `B_gpu`, `C_gpu`) с использованием `cuda.mem_alloc()`, что позволяет GPU эффективно управлять памятью.
- **Копирование данных на GPU**: 
  - Входные матрицы `A` и `B` копируются на GPU с помощью `cuda.memcpy_htod()`, что позволяет ядру CUDA получать доступ к данным.
- **Использование CUDA ядра**: 
  - Умножение выполняется в CUDA-ядре `matrixMulKernel`, где каждое ядро обрабатывает одно значение результирующей матрицы `C`, вычисляя его на основе значения из соответствующих строк и столбцов матриц `A` и `B`.
- **Оптимизация размеров блоков и сетки**: 
  - Определяются размеры блоков и сетки для эффективного распределения вычислений при запуске ядра. Это позволяет параллельно обрабатывать множество элементов.
- **Синхронизация контекста**: 
  - Вызов `cuda.Context.synchronize()` гарантирует, что все операции на GPU завершены перед возвратом результата на CPU.
- **Копирование результата с GPU**: 
  - Результат умножения матриц возвращается на CPU с помощью `cuda.memcpy_dtoh()`, что позволяет сохранить вычисленный результат в выходной массив `C`.

#### Объяснение ядра:

- **Потоки**: Каждое ядро обрабатывает один элемент результирующей матрицы, вычисляя его значение в зависимости от индексов строки и столбца, которые определяются через `blockIdx` и `threadIdx`.
- **Параллелизация**: Внутренний цикл позволяет каждому ядру выполнять суммирование произведений элементов строки первой матрицы на соответствующие элементы столбца второй матрицы.
- **Границы доступа**: Проверка на границы (если `row < rows_a` и `col < cols_b`) предотвращает доступ к выходу за пределы массивов, что важно для корректности вычислений.

---

## Почему GPU быстрее?
Умножение матриц является вычислительно сложной задачей с кубической сложностью \(O(N^3)\), но при этом все элементы результирующей матрицы могут вычисляться независимо друг от друга. Это делает задачу идеальной для параллельных вычислений, которые отлично поддерживаются на GPU. 

В отличие от CPU, который выполняет одну или несколько операций последовательно, GPU имеет тысячи ядер, способных выполнять операции одновременно, что позволяет значительно ускорить вычисления для больших матриц.

---

## Таблица времени работы на CPU и GPU

| Размер матрицы (N x M) | Время на CPU (сек) | Время на GPU (сек) | Ускорение (CPU/GPU) |
|------------------------|--------------------|--------------------|---------------------|
| 100x100                | 0,791502           | 0,001850           | 427.838919          |
| 480х480                | 84,078420          | 0,003558           | 23630.809444        |
| 860x860                | 473,219588         | 0,010889           | 43458.498301        |
| 1240x1240              | 1420,735224        | 0,024501           | 57986.826007        |
| 1620x1620              | 3183,791578        | 0,051493           | 61829.599713        |
| 2000x2000              | 5977,909498        | 0,083697           | 71423.223031        |

Все вычисления производились в Google Collab.

### Описание

- **Размер матрицы (N x M)**: Размеры матриц, для которых проводятся измерения.
- **Время на CPU (сек)**: Время выполнения операции на центральном процессоре.
- **Время на GPU (сек)**: Время выполнения операции на графическом процессоре.
- **Ускорение (CPU/GPU)**: Ускорение вычисляется как отношение времени на CPU к времени на GPU.

Результаты демонстрируют значительное ускорение вычислений на GPU по сравнению с CPU, с увеличением матриц от 100x100 до 2000x200, достигая ускорения более чем в 120000 раз при размере 2000x200.
