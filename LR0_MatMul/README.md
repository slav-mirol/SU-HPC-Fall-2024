# Умножение матриц на CPU и GPU

Этот проект реализует умножение матриц двумя способами:
- Последовательное умножение на **CPU**
- Параллельное умножение на **GPU** с использованием библиотеки `CuPy`

## Описание функций

### `matrix_multiply_cpu(A, B)`
Функция выполняет умножение двух матриц на **CPU**.
Алгоритм использует тройной цикл для вычисления каждого элемента результирующей матрицы. 

- **Параметры:**
  - `A`: Первая матрица (numpy array)
  - `B`: Вторая матрица (numpy array)
- **Возвращает**:
  - `answer`: Результат умножения матриц
  - `время выполнения`: Время, затраченное на выполнение операции.

#### Детали реализации:
- Операция умножения матриц выполняется через тройной цикл по индексам \(i\), \(j\) и \(k\). 
- Эта операция имеет кубическую сложность \(O(N^3)\), что делает её медленной для больших матриц.
- Циклы вычисляют каждый элемент результирующей матрицы путём сложения произведений элементов соответствующих строк первой матрицы и столбцов второй матрицы.

---

### `matrix_multiply_gpu(A, B)`
Функция выполняет умножение матриц на **GPU** с помощью библиотеки `CuPy`. Эта реализация использует графический процессор (GPU) для значительного ускорения вычислений.

- **Параметры:**
  - `A`: Первая матрица (numpy array)
  - `B`: Вторая матрица (numpy array)
- **Возвращает**:
  - `answer`: Результат умножения матриц
  - `время выполнения`: Время, затраченное на выполнение операции.

#### Детали реализации:
- Матрицы передаются на GPU с помощью функции `cp.asarray()`, которая конвертирует массивы `NumPy` в формат `CuPy`.
- Для умножения матриц на GPU используется функция `cp.dot()`, которая эффективно распараллеливает вычисления на всех ядрах GPU.
- Результат возвращается обратно на CPU с помощью функции `cp.asnumpy()`.
- Благодаря архитектуре GPU, каждый элемент результирующей матрицы вычисляется независимо и параллельно, что значительно ускоряет процесс по сравнению с последовательным выполнением на CPU.

---

## Почему GPU быстрее?
Умножение матриц является вычислительно сложной задачей с кубической сложностью \(O(N^3)\), но при этом все элементы результирующей матрицы могут вычисляться независимо друг от друга. Это делает задачу идеальной для параллельных вычислений, которые отлично поддерживаются на GPU. 

В отличие от CPU, который выполняет одну или несколько операций последовательно, GPU имеет тысячи ядер, способных выполнять операции одновременно, что позволяет значительно ускорить вычисления для больших матриц.

---

## Таблица для заполнения времени работы на CPU и GPU

| Размер матрицы (N x M) | Время на CPU (сек) | Время на GPU (сек) | Ускорение (CPU/GPU) |
|------------------------|--------------------|--------------------|---------------------|
| 100x100                | 0.655572           | 0.000417           | 1572.115108         |
| 480х480                | 78.525480          | 0.002143           | 36642.781148        |
| 860x860                | 452.908478         | 0.007758           | 58379.540861        |
| 1240x1240              | 1363.350222        | 0.015569           | 87568.258848        |
| 1620x1620              | 3038.758041        | 0.029308           | 103683.569026       |
| 2000x2000              | 5717.959362        | 0.047464           | 120469.394952       |


### Описание

- **Размер матрицы (N x M)**: Размеры матриц, для которых проводятся измерения.
- **Время на CPU (сек)**: Время выполнения операции на центральном процессоре.
- **Время на GPU (сек)**: Время выполнения операции на графическом процессоре.
- **Ускорение (CPU/GPU)**: Ускорение вычисляется как отношение времени на CPU к времени на GPU.

### Формула для расчета ускорения:

\[
\text{Ускорение} = \frac{\text{Время на CPU}}{\text{Время на GPU}}
\]

Результаты демонстрируют значительное ускорение вычислений на GPU по сравнению с CPU, с увеличением матриц от 100x100 до 2000x200, достигая ускорения более чем в 120000 раз при размере 2000x200.
