{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0o4ZaeaN0GR",
        "outputId": "8a026a9a-e661-4649-f962-87be9887a125"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Oct  3 10:46:26 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTGMP1o-N453",
        "outputId": "57b7a450-6e3a-4975-a2f0-df627e09bd4b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e__auDkNKWEG",
        "outputId": "81bc8f5a-57cf-4dcd-82e2-68295f1160c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2024.1.2.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2024.1.14-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (4.3.6)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.5)\n",
            "Downloading pytools-2024.1.14-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2024.1.2-cp310-cp310-linux_x86_64.whl size=660544 sha256=1d890b4d7d7c4802ed9f198d1315ebe47cdfadb83113878ed42fa81b8219cce0\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/63/40/4bf006182f942d3516b71bb2ff3b57ccbdb8b2c0ee81882b6e\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.3.5 pycuda-2024.1.2 pytools-2024.1.14\n"
          ]
        }
      ],
      "source": [
        "%pip install pycuda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "import time\n",
        "\n",
        "# CUDA-код для умножения матриц\n",
        "matrix_mul_kernel = \"\"\"\n",
        "__global__ void matrixMulKernel(float* a, float* b, float* c, int rows_a, int cols_a, int cols_b) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y; // Индекс строки в результирующей матрице\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x; // Индекс столбца в результирующей матрице\n",
        "\n",
        "    if (row < rows_a && col < cols_b) {\n",
        "        float value = 0.0f;\n",
        "\n",
        "        // Вычисление элемента результирующей матрицы\n",
        "        for (int k = 0; k < cols_a; k++) {\n",
        "            value += a[row * cols_a + k] * b[k * cols_b + col];\n",
        "        }\n",
        "        c[row * cols_b + col] = value; // Запись результата в итоговую матрицу\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "def matrix_multiply_cpu(A, B):\n",
        "    '''\n",
        "    Функция для выполнения умножения матриц на CPU\n",
        "    :param: A - первая матрица\n",
        "    :param: B - вторая матрица\n",
        "    :return: [\n",
        "        answer - результат умножения,\n",
        "        время выполнения операции\n",
        "    ]\n",
        "    '''\n",
        "    if A.shape[1] != B.shape[0]:\n",
        "        raise ValueError(\"Неправильные размеры матриц для перемножения\")\n",
        "\n",
        "    answer = np.zeros((A.shape[0], B.shape[1]))\n",
        "\n",
        "    start_time = time.time()\n",
        "    for i in range(A.shape[0]):\n",
        "        for j in range(B.shape[1]):\n",
        "            for k in range(A.shape[1]):\n",
        "                answer[i, j] += A[i, k] * B[k, j]\n",
        "    end_time = time.time()\n",
        "\n",
        "    return answer, end_time - start_time\n",
        "\n",
        "def matrix_multiply_gpu(A, B):\n",
        "    '''\n",
        "    Функция для выполнения умножения матриц на GPU\n",
        "    :param: A - первая матрица\n",
        "    :param: B - вторая матрица\n",
        "    :return: [\n",
        "        C - результат умножения,\n",
        "        время выполнения операции\n",
        "    ]\n",
        "    '''\n",
        "    if A.shape[1] != B.shape[0]:\n",
        "        raise ValueError(\"Неправильные размеры матриц для перемножения\")\n",
        "\n",
        "    A_height, A_width = A.shape\n",
        "    B_height, B_width = B.shape\n",
        "    C = np.zeros((A_height, B_width), dtype=np.float32)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Выделение памяти на GPU\n",
        "    A_gpu = cuda.mem_alloc(A.nbytes)\n",
        "    B_gpu = cuda.mem_alloc(B.nbytes)\n",
        "    C_gpu = cuda.mem_alloc(C.nbytes)\n",
        "\n",
        "    # Копирование данных на GPU\n",
        "    cuda.memcpy_htod(A_gpu, A)\n",
        "    cuda.memcpy_htod(B_gpu, B)\n",
        "\n",
        "    # Компиляция и загрузка CUDA-кода\n",
        "    mod = SourceModule(matrix_mul_kernel)\n",
        "    matrix_mul = mod.get_function(\"matrixMulKernel\")\n",
        "\n",
        "    # Определяем размеры блока и сетки для распараллеливания\n",
        "    block_size = (16, 16, 1)\n",
        "    grid_size = ((B_width + block_size[0] - 1) // block_size[0],\n",
        "                  (A_height + block_size[1] - 1) // block_size[1])\n",
        "\n",
        "    # Запуск ядра на GPU\n",
        "    matrix_mul(A_gpu, B_gpu, C_gpu, np.int32(A_height), np.int32(A_width), np.int32(B_width), block=block_size, grid=grid_size)\n",
        "\n",
        "    cuda.Context.synchronize()\n",
        "\n",
        "    # Копирование результата с GPU на CPU\n",
        "    cuda.memcpy_dtoh(C, C_gpu)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    return C, end_time - start_time\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    size = (2000, 2000)\n",
        "    low = 1\n",
        "    high = 10\n",
        "    matrix_a = np.random.randint(low, high, size).astype(np.float32)\n",
        "    matrix_b = np.random.randint(low, high, size).astype(np.float32)\n",
        "\n",
        "    # Сравнение с результатом последовательного умножения\n",
        "    answer_function = np.dot(matrix_a, matrix_b)\n",
        "\n",
        "    # Умножение на GPU\n",
        "    answer_gpu, time_gpu = matrix_multiply_gpu(matrix_a, matrix_b)\n",
        "    print(f\"Результат на GPU:\\n{answer_gpu}\")\n",
        "    print(f\"Соответствие результата с np.dot(): {np.allclose(answer_gpu, answer_function)}\")\n",
        "    print(f\"Время на GPU: {time_gpu} секунд\")\n",
        "\n",
        "    # Умножение на CPU\n",
        "    answer_cpu, time_cpu = matrix_multiply_cpu(matrix_a, matrix_b)\n",
        "    print(f\"Результат на CPU:\\n{answer_cpu}\")\n",
        "    print(f\"Соответствие результата с np.dot(): {np.allclose(answer_cpu, answer_function)}\")\n",
        "    print(f\"Время на CPU: {time_cpu} секунд\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLiOP1OLKrKr",
        "outputId": "632d139c-841a-44d0-e9bc-b2ea1bf96f83"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результат на GPU:\n",
            "[[49437. 50052. 49973. ... 50037. 50175. 49695.]\n",
            " [49243. 49867. 50322. ... 50106. 50751. 50599.]\n",
            " [49548. 49603. 50570. ... 49803. 49933. 50183.]\n",
            " ...\n",
            " [50161. 50628. 50961. ... 49622. 50732. 50074.]\n",
            " [50342. 50559. 50889. ... 49582. 50489. 50028.]\n",
            " [48973. 49888. 50068. ... 49378. 50116. 49596.]]\n",
            "Соответствие результата с np.dot(): True\n",
            "Время на GPU: 0.08369660377502441 секунд\n",
            "Результат на CPU:\n",
            "[[49437. 50052. 49973. ... 50037. 50175. 49695.]\n",
            " [49243. 49867. 50322. ... 50106. 50751. 50599.]\n",
            " [49548. 49603. 50570. ... 49803. 49933. 50183.]\n",
            " ...\n",
            " [50161. 50628. 50961. ... 49622. 50732. 50074.]\n",
            " [50342. 50559. 50889. ... 49582. 50489. 50028.]\n",
            " [48973. 49888. 50068. ... 49378. 50116. 49596.]]\n",
            "Соответствие результата с np.dot(): True\n",
            "Время на CPU: 5977.909497976303 секунд\n"
          ]
        }
      ]
    }
  ]
}