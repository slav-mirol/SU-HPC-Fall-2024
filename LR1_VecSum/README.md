# Сумма элементов вектора на CPU и GPU

Этот проект демонстрирует реализацию нахождения суммы элементов вектора двумя способами:
- Последовательное суммирование на **CPU**
- Параллельное суммирование на **GPU** с использованием технологии CUDA.

## Описание функций

### `vector_sum_cpu(vector)`
Функция для сложения элементов вектора на **CPU**. Операция выполняется последовательно с использованием цикла `for`, где каждый элемент добавляется поочередно к итоговой сумме.

- **Параметры:**
  - `vector`: Входной вектор (numpy array).
- **Возвращает**:
  - `answer`: Результат сложения элементов вектора.

#### Детали реализации:
- Сумма элементов вектора вычисляется последовательно, один элемент за раз.
- Вся операция выполняется в одном потоке, что при увеличении размера вектора может быть относительно медленным процессом из-за последовательного характера выполнения.
  
---

### `vector_sum_gpu(vector)`

Функция для сложения элементов вектора на **GPU**. Операция выполняется параллельно на графическом процессоре.

- **Параметры:**

  - `vector`: Входной вектор (numpy array).

- **Возвращает**:

  - `answer`: Результат сложения элементов вектора.

#### Детали реализации:

- **Передача данных на GPU**: Вектор копируется на GPU с помощью `cuda.memcpy_htod()`, что позволяет передать данные из оперативной памяти на графический процессор для дальнейшей обработки.

- **Использование CUDA ядра**: 
  - Сложение выполняется в CUDA-ядре `addKernel`, которое запускается на GPU. Каждое ядро обрабатывает отдельные элементы вектора, используя параллельное выполнение потоков. Параметры ядра включают указатели на входные данные и результат.
  
- **Параллелизация**: 
  - В результате вычисления каждый поток получает уникальный индекс и суммирует соответствующий элемент вектора. Затем выполняется редукция сумм в `shared` памяти, чтобы минимизировать доступ к глобальной памяти, что способствует более высокой производительности.

- **Особенности ядра**:
  - **Атомарные операции**: Для запися результата в глобальную память используется `atomicAdd`, потому что результаты из разных блоков корректно суммируются в финальное значение в глобальной памяти, предотвращая конфликты при параллельном доступе.
  - **Потоки**: Каждое ядро обрабатывает элементы вектора в зависимости от индекса, который определяется через `blockIdx` и `threadIdx`.
  - **Редукция**: Потоки выполняют сложение значений в `shared` памяти и постепенно уменьшают число активных потоков, что в итоге приводит к вычислению суммы для всего блока.

- **Возврат результата на CPU**: Результат суммирования копируется обратно на CPU с помощью `cuda.memcpy_dtoh()`, обеспечивая доступ к итоговому значению в Python.

### Почему GPU быстрее?

Сложение элементов вектора можно эффективно распараллелить, потому что каждый элемент вектора можно суммировать независимо. В отличие от CPU, где сложение выполняется последовательно, GPU использует тысячи ядер, которые могут параллельно суммировать различные части вектора. Это особенно эффективно для больших векторов.


На **GPU** операция сложения выполняется на всех доступных ядрах одновременно, что значительно ускоряет процесс. В отличие от **CPU**, который выполняет одну операцию за раз, **GPU** может разбить задачу на множество потоков и выполнять их параллельно.


## Таблица времени работы на CPU и GPU

| Размер ветора          | Время на CPU (сек) | Время на GPU (сек) | Ускорение (CPU/GPU) |
|------------------------|--------------------|--------------------|---------------------|
| 1000                   | 0,000206           | 0,003628           | 0,056781            |
| 50000                  | 0,008054           | 0,001439           | 5,596942            |
| 125000                 | 0,020256           | 0,001591           | 12,731615           |
| 250000                 | 0,039445           | 0,002232           | 17,672491           |
| 500000                 | 0,077340           | 0,002322           | 33,307494           |
| 1000000                | 0,151706           | 0,002773           | 54,708258           |

Все вычисления производились в Google Collab.

### Описание

- **Размер вектора      : Размер вектора, для которого проводятся измерения.
- **Время на CPU (сек)**: Время выполнения операции на центральном процессоре.
- **Время на GPU (сек)**: Время выполнения операции на графическом процессоре.
- **Ускорение (CPU/GPU)**: Ускорение вычисляется как отношение времени на CPU к времени на GPU.


Результаты показывают, что при увеличении размера вектора от 1000 до 1000000, производительность GPU значительно превосходит CPU, с ускорением, достигающим почти 55 раз при размере 1000000.
